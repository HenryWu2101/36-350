---
title: "HW: Week 3"
author: "36-350 -- Statistical Computing"
date: "Week 3 -- Spring 2022"
output:
  pdf_document:
    toc: no
  html_document:
    toc: true
    toc_float: true
    theme: spacelab
---

Name: Henry Wu    

Andrew ID:  zhenyuw

You must submit **your own** HW as a PDF file on Gradescope.

```{r wrap-hook,echo=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
```

---

```{r linewidth=80}
shakespeare.lines = readLines("http://www.andrew.cmu.edu/user/mfarag/shakespeare.txt")
```

---

## Question 1
*(10 points)*

Display the lines of text in `shakespeare.lines` that contain both of the strings "purse" *and* "gold" (in any order, separated by any amount of text). Do so only using regexp literals.
```{r linewidth=80}
# FILL ME IN
grep("purse&gold", shakespeare.lines, value = TRUE)
```

## Question 2
*(10 points)*

Retrieve (but don't display) the lines of text in `shakespeare.lines` that contain "briers". Then break the retrieved lines into individual words (`strsplit(input," ")` to split the character vector `input` into words separated by spaces), and merge those words into a single character vector (`unlist()`!). How many unique words are there? Display the top five most commonly occurring words and how often they occur (combine `sort()` and `table()`!)
```{r linewidth=80}
# FILL ME IN
lines = grep("briers", shakespeare.lines, value = TRUE)
S = unlist(strsplit(lines, " "))
len = length(table(S))
T = sort(table(S))
len
T[(len-4):len]
```

## Question 3
*(10 points)*

In Q25 of Lab 3, you coded a regex to match all patterns of the following form: any letter (1 or more), then a punctuation mark, then "ve" or "ll" or "t", then a space or a punctuation mark. You called it `my.pattern`. Use `my.pattern`, along with `regexpr()` and `regmatches()`, to extract and display all the occurrences of the pattern in `shakespeare.lines`. Then repeat the exercise using `gregexpr()` instead of `regexpr`; note that here, you'll want to `unlist()` the output from `regmatches()`. Do you get the same vector of character strings? Why or why not?
```{r linewidth=80}
# FILL ME IN
my.pattern = "[A-Za-z]+[[:punct:]](ve|ll|t)( |[[:punct:]])"
c1 = regmatches(shakespeare.lines,regexpr(my.pattern, shakespeare.lines))
c2 = unlist(regmatches(shakespeare.lines,gregexpr(my.pattern, shakespeare.lines)))
c1
c2
identical(c1, c2)
```
```
They are not the same vector of character strings. Since using gregexpr will return the occurrence of all matches, even when they are in the same line; while for regexpr, it only returns the occurrence of the first time of match
```

## Question 4
*(10 points)*

Come up with a strategy that splits punctuation marks or spaces, except that it keeps intact words like "I've" or "wasn't", that have a punctuation mark in the middle, in between two letters. (Or when the punctuation mark is at the beginning, as in "'em") Apply your strategy to `shakespeare.lines` as defined below such that you display only those words with punctuation marks. (Note that I end up with 704 [not necessarily unique, but total] words when I implement this strategy. Some include '\"', which we can easily remove in a subsequent post-processing step if we so choose. Hint: `[[:alnum:]]` is a good thing to use here.)
```{r linewidth=80}
# FILL ME IN
p = "([[:alnum:]]*[[:punct:]]+[[:alnum:]]+)|([[:punct:]][[:alnum:]]+)"
u = unlist(strsplit(shakespeare.lines, "[[:space:]]+"))
unlist(regmatches(u,gregexpr(p, u)))
```

---

Below, we read in lines of data from the Advanced National Seismic System (ANSS), on earthquakes of magnitude 6+, between 2002 and 2017. (You don't have to do anything yet.) 
```{r linewidth=80}
anss.lines = readLines("http://www.stat.cmu.edu/~mfarag/350/anss.htm")
date.pattern = "[0-9]{4}/[0-9]{2}/[0-9]{2}"
date.lines = grep(date.pattern,anss.lines,value=TRUE)
```

---

## Question 5
*(10 points)*

Check that all the lines in `date.lines` actually start with a date, of the form YYYY/MM/DD. rather than contain a date of this form somewhere in the middle of the text. (Hint: it might help to note that you can look for non-matches, as opposed to matches, by changing one of `grep()`'s logical arguments.)
```{r linewidth=80}
# FILL ME IN
date.p = "^[2][0-9]{3}/[0-1][0-9]/[0-3][0-9]"
grep(date.p, date.lines, invert = TRUE)
```

## Question 6
*(10 points)*

Which five days witnessed the most earthquakes, and how many were there, these days? Also, what happened on the day with the most earthquakes: can you find any references to this day in the news?
```{r linewidth=80}
# FILL ME IN

date = regmatches(date.lines,regexpr(date.p, date.lines))
T = sort(table(date), decreasing = TRUE)
T[1:5]

```
```
2011 T≈çhoku earthquake and tsunami happened on the day with the most earthquakes : 2011/03/11, with total of 42 earthquakes
```

## Question 7
*(10 points)*

Go back to the data in `date.lines`. Following steps similar to the ones you used in the lab to extract the latitude and longitude of earthquakes, extract the depth and magnitude of earthquakes. In the end, you should have one numeric vector of depths, and one numeric vector of magnitudes. Show the first three depths and the first three magnitudes. (Hint: if you use `regexpr()` and `regmatches()`, then the output from the latter will be a vector of strings. Look at this vector. The last four characters always represent the magnitudes. Use a combination of `substr()` and `as.numeric()` to create the numeric vector of magnitudes. Then use the fact that everything but the last four characters represents the depths. There are a myriad of ways to do this exercise, but this suggested way is the most concise.)
```{r linewidth=80}
# FILL ME IN

p7 = "[0-9]+\\.[0-9]{2}[[:space:]]+[0-9]\\.[0-9]{2}[[:space:]]"
A = regmatches(date.lines,regexpr(p7, date.lines))
depth = as.numeric(substr(A, (nchar(A)-4),(nchar(A)-1)))
depth[1:3]
magnitude = as.numeric(substr(A, 1,(nchar(A)-5)))
magnitude[1:3]
```

---

Here we read in text containing the fastest men's 100-meter sprint times. We retain only the lines that correspond to the sprint data, for times 9.99 seconds or better.
```{r linewidth=80}
sprint.lines = readLines("http://www.stat.cmu.edu/~mfarag/350/men_100m.html")
data.lines = grep(" +(9|10)\\.",sprint.lines)
sprint.lines = sprint.lines[min(data.lines):max(data.lines)]
```

---

## Question 8
*(10 points)*

Extract the years in which the sprint times were recorded. Display them in table format. Do the same for the months. Be sure to extract the month of the sprint, not the birth month of the sprinter! (Hint: the month of the sprint is followed by a four-digit year; other instances of two digits in any given line are not. So you may have to extract more than you need, then apply `strsplit()`.)
```{r linewidth=80}
# FILL ME IN
p8 = "[0-9]{2}\\.[0-9]{2}\\.[1-2][0-9]{3}"
inter = regmatches(sprint.lines,regexpr(p8, sprint.lines))
p_y = "[1-2][0-9]{3}"
years = regmatches(inter,regexpr(p_y, inter))
table(years)
p_m = "\\.[0-9]{2}\\."
months = substr(regmatches(inter,regexpr(p_m, inter)), 2, 3)
table(months)
```

## Question 9
*(10 points)*

Extract the countries of origin (for the sprinters). Note that countries of origin are given as a capitalized three-letter abbreviation. Display the table of country origins. Display the proportion of the list that is accounted for by sprinters from the US and Jamaica.
```{r linewidth=80}
# FILL ME IN

p_n = "[A-Z]{3}"
names = regmatches(sprint.lines,regexpr(p_n, sprint.lines))
T_n = table(names)
T_n
pro = sum(T_n["USA"], T_n["JAM"])/sum(T_n)
pro
```

## Question 10
*(10 points)*

We conclude with a web scraping exercise. I want you to go to <a href="https://arxiv.org/year/astro-ph/19">this web site</a>. On it, you see there is a set of 12 bold-faced four-digit numbers: this is the number of submitted astrophysics articles for each month of 2019. I want you to extract these numbers and place them into a single vector, with each vector element having a name: Jan for the first vector element, Feb for the second, etc. You would use `readLines()` to read in the page (pass the URL directly to the function!); this creates a vector of strings. You would then use `regexpr()` and `regmatches()` to extract the numbers (plus potentially some other stuff that you may have to pare off using `substr()`). If necessary, use "view source" to look at the html code for the web page itself to determine how best to extract the 12 numbers and nothing else. You don't want to create a table; you simply want to output the vector of four-digit numbers and add the appropriate names. (Hint: see the documentation for `Constants`. `month.abb` might be helpful here.)
```{r linewidth=80}
# FILL ME IN
net = readLines("https://arxiv.org/year/astro-ph/19")

p10 = "<b>[0-9]{4}</b>"
v = as.numeric(substr(regmatches(net, regexpr(p10, net)), 4, 7))
setNames(v[1:12], month.abb[1:12]) 

```

## Question 11
*(10 points)*

Make a string with "Regards," and then your first name, separated by a newline character. Print it to the console via `print()` and then via `cat()`. Comment on the difference.
```{r linewidth=80}
# FILL ME IN
s = "Regards, Henry \n"
print(s)
cat(s)
```
```
"print" does not treat s as string so print whatever s equals to (i.e. keeps the "" at the beginning and end, also does not interpret \n as newline but 2 chars), while "cat" treat s as string and only print out the chars in between "" and treat \n as newline.
```

## Question 12
*(10 points)*

Transform the vector so that the words have all uppercase characters.
```{r linewidth=80}
# FILL ME IN
s = toupper(s)
cat(toupper(s))
```
